{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reddit_ner.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMCaSZK1AB+Q78lrpZTUcUa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/richardOlson/nlp__tranformers/blob/main/reddit_ner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh2Qv-fOaSvD"
      },
      "source": [
        "# bringing in the client_id and the secret for the reddit\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itdWVklgap-s"
      },
      "source": [
        "files.upload()\n",
        "# erased the output so that the client_id and the secret are not visible"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKm8TJsLbSkJ"
      },
      "source": [
        "with open(\"udemy_reddit_api.txt\", mode=\"r\") as f:\n",
        "  while True:\n",
        "    line = f.readline()\n",
        "    if line == \"\":\n",
        "      break\n",
        "    # splitting the line\n",
        "    splitLine  = line.split()\n",
        "   \n",
        "    if \"personal_use_script:\" in splitLine:\n",
        "      client_id = splitLine[1]\n",
        "    elif \"secret:\" in splitLine:\n",
        "      secret = splitLine[1]\n",
        "    elif \"password:\" in splitLine:\n",
        "      reddit_pass = splitLine[1]\n",
        "    elif \"username:\" in splitLine:\n",
        "      reddit_user = splitLine[1] \n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KJ16Mq6bu4X"
      },
      "source": [
        "# requesting an oauth using request\n",
        "import requests"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqXHsUHadsUY"
      },
      "source": [
        "# doing the authenitaction\n",
        "auth = requests.auth.HTTPBasicAuth(client_id, secret)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTt6rf7aNxwW"
      },
      "source": [
        "post_data = {\"grant_type\": \"password\", \n",
        "             \"username\": reddit_user, \n",
        "             \"password\": reddit_pass}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27IEjblvNzM0"
      },
      "source": [
        "headers = {\"User-Agent\": \"myUdemyTutoria/0.0.1\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0-a5tr9QI0x",
        "outputId": "dcd85b6e-984f-4894-ab06-cb0d9f4feda3"
      },
      "source": [
        "res = requests.post(\"https://www.reddit.com/api/v1/access_token\",\n",
        "                    data=post_data, auth=auth, headers=headers)\n",
        "res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "F-zYbkzeRIL6",
        "outputId": "ffd809b4-3ddd-4fd1-f6d7-a020a257f4bd"
      },
      "source": [
        "token = res.json()[\"access_token\"]\n",
        "token"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1064711172543-J7JEgn4i8Wkvao74CDJmmf1TTHwcIQ'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UsBEI6yRR3Y"
      },
      "source": [
        "# add this to the headers\n",
        "headers[\"Authorization\"] = f\"bearer {token}\"\n",
        "headers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd6G0U_vR94k",
        "outputId": "6ea4d1a1-7f88-4f7c-ae85-3d301706c7ad"
      },
      "source": [
        "res = requests.get(\"https://oauth.reddit.com/api/v1/me\", headers=headers)\n",
        "res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7gho_3uVzJ9",
        "outputId": "8a2ffb23-3589-488b-b674-aabeadd6a522"
      },
      "source": [
        "res.status_code"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rq1tV6FYTPNC",
        "outputId": "027c070e-96c3-4d10-9d8d-4aa6db39c089"
      },
      "source": [
        "res.status_code == 200"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnGQLBBaSgxJ"
      },
      "source": [
        "# making a function that will do the same thing to get us\n",
        "# contacted to the reddit api so that we can then make calls\n",
        "def connect_reddit(reddit_username, reddit_password, app_or_client_id, secret, user_agent:str):\n",
        "  \"\"\"\n",
        "  This function will return the headers dictionary \n",
        "  that now has the token in the headers so that it is available to use with\n",
        "  any another get requests or post requests\n",
        "  \"\"\"\n",
        "  # first will get the token to do the authorization\n",
        "  # will make the auth for the requests\n",
        "  auth = requests.auth.HTTPBasicAuth(client_id, secret)\n",
        "  # making the header that tells reddidt what the User-Agent is\n",
        "  headers = {\"User-Agent\": user_agent}\n",
        "  # now making the post data dictionary\n",
        "  post_data = {\"grant_type\": \"password\", \n",
        "               \"username\": reddit_username,\n",
        "               \"password\": reddit_password}\n",
        "  # Will then try to get the token\n",
        "  res = requests.post(\"https://www.reddit.com/api/v1/access_token\", \n",
        "                      data=post_data,\n",
        "                      auth=auth,\n",
        "                      headers=headers)\n",
        "  if res.status_code != 200:\n",
        "    raise Exception(f\"Unable to get the token to make a connection to Reddit the responce is {res}\")\n",
        "  # now returning the headers which will contain the access_token\n",
        "  token = res.json()[\"access_token\"]\n",
        "  headers[\"Authorization\"] = f\"bearer {token}\"\n",
        "  return headers\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZaBal2nST2h"
      },
      "source": [
        "# running the function that will give the headers\n",
        "headers = connect_reddit(reddit_username=reddit_user, reddit_password=reddit_pass,\n",
        "                         app_or_client_id= client_id, secret=secret,\n",
        "                         user_agent=\"myUdemyTutorial/0.0.1\")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQoXU8HJdHvY",
        "outputId": "83daadeb-79f6-4a0b-d8b1-a2cd47c93bc9"
      },
      "source": [
        "# trying the headers on the api to just me\n",
        "res = requests.get(\"https://oauth.reddit.com/api/v1/me\", headers=headers)\n",
        "res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI4K9II1edxh"
      },
      "source": [
        "# setting the api -- the address where we will go to \n",
        "api = \"https://oauth.reddit.com\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3q-WqMmf1SE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f72f955d-05c1-4ada-e041-42489155b44b"
      },
      "source": [
        "# getting some of the investing data from reddit\n",
        "res = requests.get(f\"{api}/r/investing/new\", headers=headers, \n",
        "                   params={\"limit\": \"100\"})\n",
        "res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGEjfZUeU-Yu"
      },
      "source": [
        "# making the list of the keys that we want to use to get \n",
        "# the data out of the repsonce\n",
        "keep_list = [\"name\", \"created_utc\", \"subreddit\", \"title\", \"selftext\", \n",
        "             \"upvote_ratio\", \"ups\", \"downs\", \"score\" ]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm23cW5pVwbk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de636fe0-55a0-4ff4-f39c-660b9af951a9"
      },
      "source": [
        "# making a dataframe with the keep_keys as the columns\n",
        "df = pd.DataFrame(columns=keep_list)\n",
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['name', 'created_utc', 'subreddit', 'title', 'selftext', 'upvote_ratio',\n",
              "       'ups', 'downs', 'score'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Umhk_5PSk-5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb0fabe0-8243-4433-d82d-4cb854934dc0"
      },
      "source": [
        "res.json()[\"data\"][\"children\"][0][\"data\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'all_awardings': [],\n",
              " 'allow_live_comments': False,\n",
              " 'approved_at_utc': None,\n",
              " 'approved_by': None,\n",
              " 'archived': False,\n",
              " 'author': 'TareXmd',\n",
              " 'author_flair_background_color': None,\n",
              " 'author_flair_css_class': None,\n",
              " 'author_flair_richtext': [],\n",
              " 'author_flair_template_id': None,\n",
              " 'author_flair_text': None,\n",
              " 'author_flair_text_color': None,\n",
              " 'author_flair_type': 'text',\n",
              " 'author_fullname': 't2_5iplk',\n",
              " 'author_is_blocked': False,\n",
              " 'author_patreon_flair': False,\n",
              " 'author_premium': False,\n",
              " 'awarders': [],\n",
              " 'banned_at_utc': None,\n",
              " 'banned_by': None,\n",
              " 'can_gild': True,\n",
              " 'can_mod_post': False,\n",
              " 'category': None,\n",
              " 'clicked': False,\n",
              " 'content_categories': None,\n",
              " 'contest_mode': False,\n",
              " 'created': 1627678700.0,\n",
              " 'created_utc': 1627678700.0,\n",
              " 'discussion_type': None,\n",
              " 'distinguished': None,\n",
              " 'domain': 'self.investing',\n",
              " 'downs': 0,\n",
              " 'edited': False,\n",
              " 'gilded': 0,\n",
              " 'gildings': {},\n",
              " 'hidden': False,\n",
              " 'hide_score': False,\n",
              " 'id': 'outsbk',\n",
              " 'is_created_from_ads_ui': False,\n",
              " 'is_crosspostable': True,\n",
              " 'is_meta': False,\n",
              " 'is_original_content': False,\n",
              " 'is_reddit_media_domain': False,\n",
              " 'is_robot_indexable': True,\n",
              " 'is_self': True,\n",
              " 'is_video': False,\n",
              " 'likes': None,\n",
              " 'link_flair_background_color': '',\n",
              " 'link_flair_css_class': None,\n",
              " 'link_flair_richtext': [],\n",
              " 'link_flair_text': None,\n",
              " 'link_flair_text_color': 'dark',\n",
              " 'link_flair_type': 'text',\n",
              " 'locked': False,\n",
              " 'media': None,\n",
              " 'media_embed': {},\n",
              " 'media_only': False,\n",
              " 'mod_note': None,\n",
              " 'mod_reason_by': None,\n",
              " 'mod_reason_title': None,\n",
              " 'mod_reports': [],\n",
              " 'name': 't3_outsbk',\n",
              " 'no_follow': False,\n",
              " 'num_comments': 18,\n",
              " 'num_crossposts': 0,\n",
              " 'num_reports': None,\n",
              " 'over_18': False,\n",
              " 'parent_whitelist_status': 'all_ads',\n",
              " 'permalink': '/r/investing/comments/outsbk/about_to_start_my_401k_with_fidelity_is_there_a/',\n",
              " 'pinned': False,\n",
              " 'pwls': 6,\n",
              " 'quarantine': False,\n",
              " 'removal_reason': None,\n",
              " 'removed_by': None,\n",
              " 'removed_by_category': None,\n",
              " 'report_reasons': None,\n",
              " 'saved': False,\n",
              " 'score': 8,\n",
              " 'secure_media': None,\n",
              " 'secure_media_embed': {},\n",
              " 'selftext': \"I just moved to the US so just wanted to make sure I do it right the first time.\\n\\nI used to use Betterment five years ago, but it was straight from my earnings after tax deduction but I made a good 4-7% annual off of it.\\n\\nNow that I'm married, and having moved to the US, my position is offering me an option to start a 401K with Fidelity. But postpandemic, I feel that now is a good time to start with a robo investing pension plan instead, so long as it has access to my pre-tax income. Is that even possible?\",\n",
              " 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just moved to the US so just wanted to make sure I do it right the first time.&lt;/p&gt;\\n\\n&lt;p&gt;I used to use Betterment five years ago, but it was straight from my earnings after tax deduction but I made a good 4-7% annual off of it.&lt;/p&gt;\\n\\n&lt;p&gt;Now that I&amp;#39;m married, and having moved to the US, my position is offering me an option to start a 401K with Fidelity. But postpandemic, I feel that now is a good time to start with a robo investing pension plan instead, so long as it has access to my pre-tax income. Is that even possible?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;',\n",
              " 'send_replies': True,\n",
              " 'spoiler': False,\n",
              " 'stickied': False,\n",
              " 'subreddit': 'investing',\n",
              " 'subreddit_id': 't5_2qhhq',\n",
              " 'subreddit_name_prefixed': 'r/investing',\n",
              " 'subreddit_subscribers': 1891164,\n",
              " 'subreddit_type': 'public',\n",
              " 'suggested_sort': None,\n",
              " 'thumbnail': '',\n",
              " 'title': '\\u200eAbout to start my 401K with Fidelity. Is there a better robo-investment option like Betterment that can use pre-tax income?',\n",
              " 'top_awarded_type': None,\n",
              " 'total_awards_received': 0,\n",
              " 'treatment_tags': [],\n",
              " 'ups': 8,\n",
              " 'upvote_ratio': 0.64,\n",
              " 'url': 'https://www.reddit.com/r/investing/comments/outsbk/about_to_start_my_401k_with_fidelity_is_there_a/',\n",
              " 'user_reports': [],\n",
              " 'view_count': None,\n",
              " 'visited': False,\n",
              " 'whitelist_status': 'all_ads',\n",
              " 'wls': 6}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygLyR0CBthKd"
      },
      "source": [
        "# checking the speed of the running\n",
        "import time"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvy_ZWbvWjrr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "6bd924f7-d3db-4b50-bc6b-b3d79c7675e1"
      },
      "source": [
        "# will now loop through the data and then put into the dataframe\n",
        "for i in range(len(res.json()[\"data\"][\"children\"])):\n",
        "  # for each of the children we will then add all the information\n",
        "  # into the dataframe\n",
        "  start = time.time()\n",
        "  theDict = res.json()[\"data\"][\"children\"][i][\"data\"]\n",
        "  insertDict = {\"name\":theDict[\"name\"], \"created_utc\":theDict[\"created_utc\"], \n",
        "                \"subreddit\":theDict[\"subreddit\"], \"title\":theDict[\"title\"],\n",
        "                \"selftext\":theDict[\"selftext\"], \"upvote_ratio\":theDict['upvote_ratio'],\n",
        "                \"ups\":theDict['ups'], \"downs\":theDict[\"downs\"], \"score\":theDict[\"score\"]}\n",
        "  \n",
        "  # now doing append on the dataframe\n",
        "  df = df.append(insertDict, ignore_index=True)\n",
        "  \n",
        "end = time.time()\n",
        "\n",
        "# checking to see how long this method takes\n",
        "t = end - start\n",
        "print(f\"The amount of time that it took to run this is {t}\")\n",
        "# now looking at the dataframe to see what is in it\n",
        "print(f\"the shape of the dataframe is {df.shape}\")\n",
        "df.tail()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-6027474f6713>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# will now loop through the data and then put into the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"children\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;31m# for each of the children we will then add all the information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;31m# into the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi7frZQMUAaZ"
      },
      "source": [
        "# making it to loop through the data so that we can then collect \n",
        "# data from the reddit api\n",
        "# will make a function that will do this\n",
        "def get_reddit_data(headers, cols_to_get ,responce=None, url_to_call=None, subreddit=None, \n",
        "                    number_of_loops=-1, limit=100, df=None , df_len=None):\n",
        "  \"\"\" \n",
        "  This is the function that will get data from reddit and will put it to a dataframe.\n",
        "\n",
        "  Arg:\n",
        "\n",
        "  \"headers\":  The headers used to get the responce.  The headers contain the Token and the User-Agent.\n",
        "\n",
        "\n",
        "  cols_to_get:  This is a list of the keys that are found in the data that are wanted to \n",
        "  be gathered from the reddit data that is returned.  These are should be the same names as the colums \n",
        "  found in the dataFrame also so that it knows where to put them in the dataFrame.\n",
        "\n",
        "  responce:  if we have made the first call through api to gather the data then, the \n",
        "  function will run from this reponce to get the data.  If the responce is None then this funtion will \n",
        "  use the \"url_to_call\" and the \"subreddit\"  and the \"headers\" to get the first repsonce.\n",
        "\n",
        "  \"url_to_call\":  this is the url to call the api of reddit.  \n",
        "\n",
        "  \"subreddit\":  this is the subreddit that we want to get the data from.\n",
        "\n",
        "  \n",
        "  \"number_of_loops\":  This is the number of times that this function will try to get data from reddit.  \n",
        "  This function will get the lesser of either the \"number_of_loops\" or when reddit stops allowing gathering data.\n",
        "  -1 for number_of_loops means that this function will try to gather data until reddit refuses.\n",
        "\n",
        "  \"limit\":  This is the number of children to gather each of the get requests\n",
        "\n",
        "   df: This is the dataFrame that the data is added to. If it is none then a new dataframe is created\n",
        "\n",
        "   df_len:  Can choose a rough estimate of the size of the dataframe using the calls from reddit.\n",
        "   When using this one number_of_loops will be set internally as -1.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  if df_len:\n",
        "    number_of_loops = -1\n",
        "\n",
        "  if df == None:\n",
        "    df = pd.DataFrame(columns=cols_to_get)\n",
        "\n",
        "  # the global variable for the function\n",
        "  after = None\n",
        "  theParams = {\"limit\":str(limit)}\n",
        "  counter = 0 # this is to count the number of times that the function will be \n",
        "              # gathering data from reddit\n",
        "\n",
        "  if responce == None:\n",
        "    if url_to_call == None or subreddit == None:\n",
        "      raise Exception(\"Url and or the subreddit must not be None if no responce is passed in\")\n",
        "\n",
        "    # getting the first reponce\n",
        "    responce = requests.get(url=f\"{url_to_call}/r/{subreddit}\", params=theParams, headers=headers)\n",
        "  if responce.status_code != 200:\n",
        "    raise Exception(f\"The repsonce was not a 200 for getting data from reddit but was a {responce.status_code}\")\n",
        "  # now gathering the data from reddit for the number of requests\n",
        "  while True:\n",
        "  #   'data': {'after': 't3_opohad',\n",
        "  # 'before': None,\n",
        "  # 'children': [{'data': {'all_awardings': [],\n",
        "  #    'allow_live_comments': False,\n",
        "  #    'approved_at_utc': None,\n",
        "    # will be setting the before and the after variable first \n",
        "    theDict = responce.json()\n",
        "\n",
        "    after = theDict[\"data\"][\"after\"]\n",
        "    # getting the data from the responce\n",
        "    # looping through all the children and then will put them into the dataframe\n",
        "    for i in range(len(theDict[\"data\"][\"children\"])):\n",
        "      # incrementing the counter \n",
        "      counter +=1\n",
        "      childDict = theDict[\"data\"][\"children\"][i][\"data\"]\n",
        "      # making the dictionary to append to the datframe\n",
        "      dict_to_append = {theItem:childDict[theItem] for theItem in cols_to_get}\n",
        "      # appending to the dataframe\n",
        "      df = df.append(other=dict_to_append, ignore_index=True)\n",
        "\n",
        "      if df_len < df.shape[0]:\n",
        "        number_of_loops = 1\n",
        "        break\n",
        "    \n",
        "    # now we are going to make the next call to reddit for more info\n",
        "    if number_of_loops != -1 and counter >= number_of_loops:\n",
        "      print(f\"Leaving the function with the counter having reached {counter} and the number of loops is set at {number_of_loops}\")\n",
        "      break\n",
        "    \n",
        "    theParams[\"after\"] = after # putting in the after param to tell what to return from reddit\n",
        "    responce = requests.get(f\"{url_to_call}/r/{subreddit}\", params=theParams, headers=headers)\n",
        "\n",
        "    # checking to see what the responce is here\n",
        "    if responce.status_code != 200 or len(responce.json()[\"data\"][\"children\"]) == 0:\n",
        "      num_children= len(responce.json()[\"data\"][\"children\"])\n",
        "      print(f\"have left the fucntion because the responce was {responce.status_code} or the number of children was {num_children}\")\n",
        "      break  # this should mean that reddit says that we are done getting data\n",
        "  \n",
        "  # out of the while loop\n",
        "  return df"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mXvUaGWBS-b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c354ee73-3b61-4d73-8163-9c4978058256"
      },
      "source": [
        "# using the method above to get the data\n",
        "df = get_reddit_data(headers=headers, cols_to_get=keep_list, url_to_call=\"https://oauth.reddit.com\", subreddit=\"investing/new\", number_of_loops=110, df_len=10000)\n",
        "print(df.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Leaving the function with the counter having reached 10001 and the number of loops is set at 1\n",
            "(10001, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHhvXesURELB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b8f07a6b-ab56-48a4-c371-cc3733f8d8e1"
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>title</th>\n",
              "      <th>selftext</th>\n",
              "      <th>upvote_ratio</th>\n",
              "      <th>ups</th>\n",
              "      <th>downs</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>t3_o808c7</td>\n",
              "      <td>1.624668e+09</td>\n",
              "      <td>investing</td>\n",
              "      <td>Is it normal to not get excited about the stoc...</td>\n",
              "      <td>I've read a lot about boring stocks:\\n\\n[https...</td>\n",
              "      <td>0.73</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>t3_o7zdfv</td>\n",
              "      <td>1.624665e+09</td>\n",
              "      <td>investing</td>\n",
              "      <td>Investing in pharmaceutical stocks prior to PDUFA</td>\n",
              "      <td>It seems like one could look at the upcoming a...</td>\n",
              "      <td>0.58</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>t3_o7yn4z</td>\n",
              "      <td>1.624662e+09</td>\n",
              "      <td>investing</td>\n",
              "      <td>I donâ€™t think I understand Market Cap.</td>\n",
              "      <td>Okay, maybe I'm just dull, but I don't get how...</td>\n",
              "      <td>0.69</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>t3_o7yli2</td>\n",
              "      <td>1.624662e+09</td>\n",
              "      <td>investing</td>\n",
              "      <td>I invest based on quantitative sentiment score...</td>\n",
              "      <td>Hey guys! Posted a little while ago about my p...</td>\n",
              "      <td>0.71</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10000</th>\n",
              "      <td>t3_o7yjao</td>\n",
              "      <td>1.624662e+09</td>\n",
              "      <td>investing</td>\n",
              "      <td>S&amp;amp;P Global Luxury index - where to find al...</td>\n",
              "      <td>Does anybody know where to find **all** consti...</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            name   created_utc  subreddit  ... ups downs  score\n",
              "9996   t3_o808c7  1.624668e+09  investing  ...  42     0     42\n",
              "9997   t3_o7zdfv  1.624665e+09  investing  ...   2     0      2\n",
              "9998   t3_o7yn4z  1.624662e+09  investing  ...  12     0     12\n",
              "9999   t3_o7yli2  1.624662e+09  investing  ...  10     0     10\n",
              "10000  t3_o7yjao  1.624662e+09  investing  ...   1     0      1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s68pRbaV-4S"
      },
      "source": [
        "# saving the dataframe\n",
        "# going to replace all the pipes with empty string \n",
        "df = df.replace(to_replace={\"|\":\"\"}, regex=True)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eoy0jA8cXHF6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04da85f8-b3b5-426b-d1a6-44d4dfe0663a"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14092, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYY-e6GmXOiL"
      },
      "source": [
        "# making it a csv with pipes\n",
        "df.to_csv(\"reddit.csv\", sep=\"|\", index=False)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiSEeYIAXT_S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}